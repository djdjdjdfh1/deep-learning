{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "aJTnVqAEzog4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vggnet = tf.keras.applications.VGG16(weights='imagenet')"
      ],
      "metadata": {
        "id": "kqfqpEwhzurT"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일을 넘파이 배열로 변환\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "dog_png = Image.open('/content/cat.png')\n",
        "dog_array = np.array(dog_png)"
      ],
      "metadata": {
        "id": "ULMpvP1k0MUv"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_prep_dog = tf.keras.applications.vgg16.preprocess_input(dog_array)\n",
        "vgg_prep_dog.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnl7I3T51y4M",
        "outputId": "fcbdd45a-1142-4d76-dae3-3cc849276eb4"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = vggnet.predict(vgg_prep_dog[np.newaxis, :]) # 배치차원 추가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loBMeegC2W1B",
        "outputId": "38222df7-1a2a-4510-ecfb-ab5e23e0f1fa"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(prediction[0]), prediction[0][208]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m98xtxuG2ccI",
        "outputId": "d35fe6bf-d472-47fd-9c56-1da1333ba6c2"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.int64(281), np.float32(3.6522097e-06))"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "decode_predictions(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox2gqlHA3DUd",
        "outputId": "dc452697-1350-4fb6-f252-d6bb31215366"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02123045', 'tabby', np.float32(0.43275443)),\n",
              "  ('n02124075', 'Egyptian_cat', np.float32(0.31127918)),\n",
              "  ('n02123159', 'tiger_cat', np.float32(0.21606451)),\n",
              "  ('n02971356', 'carton', np.float32(0.0035795602)),\n",
              "  ('n03223299', 'doormat', np.float32(0.0031308173))]]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet\n",
        "# 층을 깊게 쌓으면 -> 더 복잡한 패턴을 학습\n",
        "# 네트웍이 깊어지면\n",
        "  # 기울기 소실(소실 / 폭발)\n",
        "# Residual Learning  잔차 연결\n",
        "# x -> H(x) - x  Residual 잔차를 학습\n",
        "# 최종 출력 H(x) = F(x) + x  스킵커넥션"
      ],
      "metadata": {
        "id": "6qoFV0oa3-0X"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델\n",
        "import keras\n",
        "from keras import layers\n",
        "inputs = layers.Input(shape=(224,224,3))\n",
        "x = layers.ZeroPadding2D(padding=3)(inputs)\n",
        "x = layers.Conv2D(64, kernel_size=7, strides=2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.MaxPool2D(pool_size=3, strides=2)(x)"
      ],
      "metadata": {
        "id": "PkfgFlxI6Wx0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, first_stride=1, conv_skip=False):\n",
        "    skip_conn = x\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=1,\n",
        "                      strides=first_stride)(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=3,\n",
        "                      padding='same')(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=1)(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "    # conv_skip이 True이면 1x1 합성곱을 사용해 채널 크기를 filters*4로 늘려준다\n",
        "    if conv_skip == True:\n",
        "        skip_conn = layers.Conv2D(filters=filters, kernel_size=1,\n",
        "                                  strides=first_stride)(skip_conn)\n",
        "        skip_conn = layers.BatchNormalization(epsilon=1e-5)(skip_conn)\n",
        "    x = layers.Add()([skip_conn, x])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "tZtIjFim9AN4"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잔차 스택\n",
        "def build_stack(x):\n",
        "    # 첫번째 잔차스택의 첫번째 잔차블럭만 스트라이드1\n",
        "    x = residual_stack(x, 3, 64, first_stride=1)\n",
        "    for blocks, filters in [(4, 128), (6, 256), (3, 512)]:\n",
        "        x = residual_stack(x, blocks, filters, first_stride=2)\n",
        "    return x\n",
        "\n",
        "def residual_stack(x, blocks, filters, first_stride=2):\n",
        "    x = residual_block(x, filters, first_stride=first_stride, conv_skip=True)\n",
        "    for _ in range(1, blocks):\n",
        "        x = residual_block(x, filters, first_stride=1, conv_skip=False)\n",
        "    return x"
      ],
      "metadata": {
        "id": "OBE4NuY28Pm8"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델\n",
        "x = build_stack(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1000, activation='softmax')(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-ncZ8oBNAq7p"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 넘파이배열로 모델에 넣으면 된다.\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "img = load_img('/content/cat.png', target_size=(224,224))\n",
        "X = img_to_array(img)\n",
        "X = np.expand_dims(X, axis=0)\n",
        "np.argmax(model.predict(X))"
      ],
      "metadata": {
        "id": "jKevZAiNCu07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pXdNIHeNCtjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[np.newaxis,:].shape, np.expand_dims(X, axis=0).shape"
      ],
      "metadata": {
        "id": "Pigb91WFDSRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}