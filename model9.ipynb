{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ebe12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀\n",
    "# 출력의 개수를 1개로\n",
    "# 손실함수를 MSE나 기타 등등..\n",
    "# 데이터셋 과 데이터 로드를 커스텀하게 정의해서 사용\n",
    "# 나머지는 동일한 패턴으로 ... 학습 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcc8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19f5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 데이터 프레임\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "class BostonDataSet(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1,1)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a468c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = BostonDataSet(data, target)  # 데이터를 X, y 를 한쌍으로 묶어\n",
    "X_train_loader = DataLoader(X_dataset ,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a834d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델 정의\n",
    "import torch.nn as nn\n",
    "class BostonRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BostonRegression,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabfe71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "model = BostonRegression(data.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a23471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1/100: 100%|██████████| 16/16 [00:00<00:00, 243.10it/s, loss=192.5085]\n",
      "epoch : 2/100: 100%|██████████| 16/16 [00:00<00:00, 474.29it/s, loss=68.9555]\n",
      "epoch : 3/100: 100%|██████████| 16/16 [00:00<00:00, 398.85it/s, loss=74.6097]\n",
      "epoch : 4/100: 100%|██████████| 16/16 [00:00<00:00, 356.51it/s, loss=80.4784]\n",
      "epoch : 5/100: 100%|██████████| 16/16 [00:00<00:00, 396.34it/s, loss=39.7274]\n",
      "epoch : 6/100: 100%|██████████| 16/16 [00:00<00:00, 320.51it/s, loss=42.2321]\n",
      "epoch : 7/100: 100%|██████████| 16/16 [00:00<00:00, 364.04it/s, loss=59.0647]\n",
      "epoch : 8/100: 100%|██████████| 16/16 [00:00<00:00, 373.18it/s, loss=85.2752]\n",
      "epoch : 9/100: 100%|██████████| 16/16 [00:00<00:00, 400.20it/s, loss=109.7504]\n",
      "epoch : 10/100: 100%|██████████| 16/16 [00:00<00:00, 319.25it/s, loss=35.0377]\n",
      "epoch : 11/100: 100%|██████████| 16/16 [00:00<00:00, 401.58it/s, loss=31.8284]\n",
      "epoch : 12/100: 100%|██████████| 16/16 [00:00<00:00, 366.77it/s, loss=30.9389]\n",
      "epoch : 13/100: 100%|██████████| 16/16 [00:00<00:00, 398.50it/s, loss=19.3874]\n",
      "epoch : 14/100: 100%|██████████| 16/16 [00:00<00:00, 398.31it/s, loss=64.1041]\n",
      "epoch : 15/100: 100%|██████████| 16/16 [00:00<00:00, 387.43it/s, loss=72.3525]\n",
      "epoch : 16/100: 100%|██████████| 16/16 [00:00<00:00, 328.07it/s, loss=90.2033]\n",
      "epoch : 17/100: 100%|██████████| 16/16 [00:00<00:00, 349.74it/s, loss=28.7856]\n",
      "epoch : 18/100: 100%|██████████| 16/16 [00:00<00:00, 183.20it/s, loss=14.9624]\n",
      "epoch : 19/100: 100%|██████████| 16/16 [00:00<00:00, 188.21it/s, loss=58.6863]\n",
      "epoch : 20/100: 100%|██████████| 16/16 [00:00<00:00, 292.49it/s, loss=26.8272]\n",
      "epoch : 21/100: 100%|██████████| 16/16 [00:00<00:00, 162.36it/s, loss=49.3671]\n",
      "epoch : 22/100: 100%|██████████| 16/16 [00:00<00:00, 160.06it/s, loss=57.1401]\n",
      "epoch : 23/100: 100%|██████████| 16/16 [00:00<00:00, 312.91it/s, loss=36.1587]\n",
      "epoch : 24/100: 100%|██████████| 16/16 [00:00<00:00, 424.70it/s, loss=60.6742]\n",
      "epoch : 25/100: 100%|██████████| 16/16 [00:00<00:00, 319.02it/s, loss=67.5593]\n",
      "epoch : 26/100: 100%|██████████| 16/16 [00:00<00:00, 320.47it/s, loss=29.0002]\n",
      "epoch : 27/100: 100%|██████████| 16/16 [00:00<00:00, 321.31it/s, loss=32.9644]\n",
      "epoch : 28/100: 100%|██████████| 16/16 [00:00<00:00, 311.88it/s, loss=24.0204]\n",
      "epoch : 29/100: 100%|██████████| 16/16 [00:00<00:00, 351.44it/s, loss=66.4026]\n",
      "epoch : 30/100: 100%|██████████| 16/16 [00:00<00:00, 397.64it/s, loss=87.1882]\n",
      "epoch : 31/100: 100%|██████████| 16/16 [00:00<00:00, 448.29it/s, loss=58.0253]\n",
      "epoch : 32/100: 100%|██████████| 16/16 [00:00<00:00, 385.13it/s, loss=78.8323]\n",
      "epoch : 33/100: 100%|██████████| 16/16 [00:00<00:00, 337.87it/s, loss=38.9773]\n",
      "epoch : 34/100: 100%|██████████| 16/16 [00:00<00:00, 424.02it/s, loss=43.3693]\n",
      "epoch : 35/100: 100%|██████████| 16/16 [00:00<00:00, 355.52it/s, loss=22.0131]\n",
      "epoch : 36/100: 100%|██████████| 16/16 [00:00<00:00, 289.38it/s, loss=51.3107]\n",
      "epoch : 37/100: 100%|██████████| 16/16 [00:00<00:00, 306.90it/s, loss=19.7605]\n",
      "epoch : 38/100: 100%|██████████| 16/16 [00:00<00:00, 302.74it/s, loss=27.7239]\n",
      "epoch : 39/100: 100%|██████████| 16/16 [00:00<00:00, 284.60it/s, loss=30.5819]\n",
      "epoch : 40/100: 100%|██████████| 16/16 [00:00<00:00, 320.20it/s, loss=69.1043]\n",
      "epoch : 41/100: 100%|██████████| 16/16 [00:00<00:00, 335.72it/s, loss=36.8280]\n",
      "epoch : 42/100: 100%|██████████| 16/16 [00:00<00:00, 400.66it/s, loss=66.6577]\n",
      "epoch : 43/100: 100%|██████████| 16/16 [00:00<00:00, 396.82it/s, loss=27.1084]\n",
      "epoch : 44/100: 100%|██████████| 16/16 [00:00<00:00, 321.76it/s, loss=14.2070]\n",
      "epoch : 45/100: 100%|██████████| 16/16 [00:00<00:00, 311.26it/s, loss=29.6880]\n",
      "epoch : 46/100: 100%|██████████| 16/16 [00:00<00:00, 178.98it/s, loss=36.2322]\n",
      "epoch : 47/100: 100%|██████████| 16/16 [00:00<00:00, 215.42it/s, loss=16.4456]\n",
      "epoch : 48/100: 100%|██████████| 16/16 [00:00<00:00, 207.40it/s, loss=27.2957]\n",
      "epoch : 49/100: 100%|██████████| 16/16 [00:00<00:00, 260.70it/s, loss=39.7581]\n",
      "epoch : 50/100: 100%|██████████| 16/16 [00:00<00:00, 191.49it/s, loss=21.9030]\n",
      "epoch : 51/100: 100%|██████████| 16/16 [00:00<00:00, 299.84it/s, loss=34.3464]\n",
      "epoch : 52/100: 100%|██████████| 16/16 [00:00<00:00, 270.58it/s, loss=29.9107]\n",
      "epoch : 53/100: 100%|██████████| 16/16 [00:00<00:00, 265.70it/s, loss=50.0912]\n",
      "epoch : 54/100: 100%|██████████| 16/16 [00:00<00:00, 227.75it/s, loss=57.7921]\n",
      "epoch : 55/100: 100%|██████████| 16/16 [00:00<00:00, 265.69it/s, loss=20.4593]\n",
      "epoch : 56/100: 100%|██████████| 16/16 [00:00<00:00, 401.92it/s, loss=20.0892]\n",
      "epoch : 57/100: 100%|██████████| 16/16 [00:00<00:00, 341.05it/s, loss=34.2558]\n",
      "epoch : 58/100: 100%|██████████| 16/16 [00:00<00:00, 353.82it/s, loss=16.4809]\n",
      "epoch : 59/100: 100%|██████████| 16/16 [00:00<00:00, 239.38it/s, loss=21.5214]\n",
      "epoch : 60/100: 100%|██████████| 16/16 [00:00<00:00, 193.14it/s, loss=25.0886]\n",
      "epoch : 61/100: 100%|██████████| 16/16 [00:00<00:00, 295.53it/s, loss=21.9977]\n",
      "epoch : 62/100: 100%|██████████| 16/16 [00:00<00:00, 211.85it/s, loss=14.4155]\n",
      "epoch : 63/100: 100%|██████████| 16/16 [00:00<00:00, 240.24it/s, loss=46.7033]\n",
      "epoch : 64/100: 100%|██████████| 16/16 [00:00<00:00, 227.93it/s, loss=19.4324]\n",
      "epoch : 65/100: 100%|██████████| 16/16 [00:00<00:00, 144.33it/s, loss=26.6300]\n",
      "epoch : 66/100: 100%|██████████| 16/16 [00:00<00:00, 151.40it/s, loss=34.1347]\n",
      "epoch : 67/100: 100%|██████████| 16/16 [00:00<00:00, 160.01it/s, loss=14.4066]\n",
      "epoch : 68/100: 100%|██████████| 16/16 [00:00<00:00, 153.68it/s, loss=37.2221]\n",
      "epoch : 69/100: 100%|██████████| 16/16 [00:00<00:00, 192.64it/s, loss=13.9629]\n",
      "epoch : 70/100: 100%|██████████| 16/16 [00:00<00:00, 146.08it/s, loss=17.9508]\n",
      "epoch : 71/100: 100%|██████████| 16/16 [00:00<00:00, 127.97it/s, loss=33.0119]\n",
      "epoch : 72/100: 100%|██████████| 16/16 [00:00<00:00, 180.43it/s, loss=33.2424]\n",
      "epoch : 73/100: 100%|██████████| 16/16 [00:00<00:00, 229.83it/s, loss=53.1512]\n",
      "epoch : 74/100: 100%|██████████| 16/16 [00:00<00:00, 185.77it/s, loss=19.3885]\n",
      "epoch : 75/100: 100%|██████████| 16/16 [00:00<00:00, 144.14it/s, loss=32.6734]\n",
      "epoch : 76/100: 100%|██████████| 16/16 [00:00<00:00, 220.44it/s, loss=31.4265]\n",
      "epoch : 77/100: 100%|██████████| 16/16 [00:00<00:00, 288.96it/s, loss=48.1964]\n",
      "epoch : 78/100: 100%|██████████| 16/16 [00:00<00:00, 246.09it/s, loss=21.9830]\n",
      "epoch : 79/100: 100%|██████████| 16/16 [00:00<00:00, 357.54it/s, loss=19.6863]\n",
      "epoch : 80/100: 100%|██████████| 16/16 [00:00<00:00, 475.14it/s, loss=25.6218]\n",
      "epoch : 81/100: 100%|██████████| 16/16 [00:00<00:00, 254.34it/s, loss=29.4056]\n",
      "epoch : 82/100: 100%|██████████| 16/16 [00:00<00:00, 274.31it/s, loss=42.7729]\n",
      "epoch : 83/100: 100%|██████████| 16/16 [00:00<00:00, 183.28it/s, loss=20.8710]\n",
      "epoch : 84/100: 100%|██████████| 16/16 [00:00<00:00, 222.22it/s, loss=29.0940]\n",
      "epoch : 85/100: 100%|██████████| 16/16 [00:00<00:00, 182.34it/s, loss=26.7663]\n",
      "epoch : 86/100: 100%|██████████| 16/16 [00:00<00:00, 245.85it/s, loss=20.5457]\n",
      "epoch : 87/100: 100%|██████████| 16/16 [00:00<00:00, 278.56it/s, loss=16.2789]\n",
      "epoch : 88/100: 100%|██████████| 16/16 [00:00<00:00, 110.77it/s, loss=20.0910]\n",
      "epoch : 89/100: 100%|██████████| 16/16 [00:00<00:00, 316.81it/s, loss=30.7155]\n",
      "epoch : 90/100: 100%|██████████| 16/16 [00:00<00:00, 251.51it/s, loss=23.7129]\n",
      "epoch : 91/100: 100%|██████████| 16/16 [00:00<00:00, 252.39it/s, loss=27.2100]\n",
      "epoch : 92/100: 100%|██████████| 16/16 [00:00<00:00, 296.87it/s, loss=16.3098]\n",
      "epoch : 93/100: 100%|██████████| 16/16 [00:00<00:00, 179.71it/s, loss=20.7370]\n",
      "epoch : 94/100: 100%|██████████| 16/16 [00:00<00:00, 158.53it/s, loss=18.4875]\n",
      "epoch : 95/100: 100%|██████████| 16/16 [00:00<00:00, 305.00it/s, loss=24.9027]\n",
      "epoch : 96/100: 100%|██████████| 16/16 [00:00<00:00, 196.24it/s, loss=34.5016]\n",
      "epoch : 97/100: 100%|██████████| 16/16 [00:00<00:00, 259.03it/s, loss=28.3668]\n",
      "epoch : 98/100: 100%|██████████| 16/16 [00:00<00:00, 247.97it/s, loss=21.8635]\n",
      "epoch : 99/100: 100%|██████████| 16/16 [00:00<00:00, 241.80it/s, loss=29.7508]\n",
      "epoch : 100/100: 100%|██████████| 16/16 [00:00<00:00, 271.60it/s, loss=32.0731]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 100 : avg loss : 27.2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "epochs = 100\n",
    "# 학습루프\n",
    "for epoch in range(epochs):\n",
    "    tqdm_obj = tqdm(X_train_loader,desc=f'epoch : {epoch+1}/{epochs}')\n",
    "    loss_lists = 0\n",
    "    for data, label in tqdm_obj:\n",
    "        optim.zero_grad()\n",
    "        preds = model(data.to(device))\n",
    "        loss = criterion(preds, label.to(device))\n",
    "        loss_lists += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()    \n",
    "        tqdm_obj.set_postfix({'loss' : f'{loss.item():.4f}'})\n",
    "    avg_loss = loss_lists / len(X_train_loader)\n",
    "print(f'epoch : {epoch+1} : avg loss : {avg_loss:.4f}')\n",
    "        \n",
    "\n",
    "torch.save(model.state_dict(), 'bostonRegression.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa9c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:00<00:00, 889.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 21.516812682151794 r2 score : 0.7200615480542183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# 평가\n",
    "model.load_state_dict(torch.load('bostonRegression.pth',map_location=device,weights_only=True))\n",
    "# 예측\n",
    "# 평가 루프\n",
    "model.eval()  # 평가 모드로 전환 (dropout, batchnorm 등 비활성화)\n",
    "total_mse = 0\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "r2scores = 0\n",
    "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "    for data, label in tqdm(X_train_loader, desc=\"Evaluating\"):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        preds = model(data)\n",
    "        r2scores += r2_score(label.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "        mse = criterion(preds, label)        \n",
    "        total_mse += mse.item()\n",
    "print(f\"Test Loss: {total_mse / len(X_train_loader)} r2 score : {r2scores/len(X_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e737def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
