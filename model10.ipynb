{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562d4287",
   "metadata": {},
   "source": [
    "##### DNN CNN\n",
    "    - 독립적인 정보\n",
    "    - 입력(x) 간의 순서나 연관성을 고려하지 않는다\n",
    "##### 시계열 : 시간의 연속적인 흐름\n",
    "    - 시계열 데이터 : 날씨, 주식, 문장 --> 순서가 중요한 데이터\n",
    "##### RNN \n",
    "    - 순환하는 구조\n",
    "        - 시점1 (월요일) : 맑음(x1)  정보가 RNN에 들어온다 -> RNN 날씨가 맑았음(h1) 이라는 요약본을 생성\n",
    "        - 시점2 (화요일) : 흐림(x2)  ->RNN 새로운정보(흐림, x2) + 어제의기억(맑았음, h1) 함께 고려\n",
    "            어제 맑았는데 오늘 흐림 h2 이라는 새로운 요약본을 생성\n",
    "        - 시점3 (수요일) : 비(x3) ->RNN 새로운정보(비, x3) 정보와 + 어제의기억(어제 맑았는데 오늘 흐림, h2) 새로운 상태 h3\n",
    "        - 반복 \n",
    "    - 알고리즘\n",
    "        - 각 시점(time step)에서  1. 현재의 입력 과 2. 과거의 기억(hidden state ht-1) 받아서 3. 현재의 결과물과 4. 다음 시점으로 넘겨줄 최신 기억 ht 을 생성\n",
    "        - ht 기억이 시계열 데이터의 맥락(Context) 저장하는 역할\n",
    "    - 장점\n",
    "        - 순서가 있는 데이터의 맥락을 학습\n",
    "    - 한계\n",
    "        - 기억력이 생각보다 짧다\n",
    "        - 시계열 데이터가 길어지면(예 100단계 전의 정보)\n",
    "        - 이전정보가 소실되거나 반대로 너무 강해져서 폭주가 되서 제대로 학습이 안된다\n",
    "        - 장기 기억 의존성 문제 (Long-Term Dependency Problem)\n",
    "##### LSTM & GRU\n",
    "    - LSTM(Long Short Term Memory) : RNN 내부에 게이트(Gate) 복잡한 장치 -> 잊고, 기억할 정보를 관리\n",
    "    - GRU(Gated Recurrent Unit) : LSTM 구조를 좀 더 단순화시킨 모델, LSTM성능은 비슷, 속도는 빠르다\n",
    "##### RNN 핵심수식\n",
    "    - 은닉상태계산\n",
    "        - h1 = tanh(wht-1 + wxt - bh)\n",
    "    - 출력계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/pia222sk20/python/refs/heads/main/data/time_data_train.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c164ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋 확인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d76bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "class StockDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        url = 'https://raw.githubusercontent.com/pia222sk20/python/refs/heads/main/data/time_data_train.csv'\n",
    "        self.csv = pd.read_csv(url)\n",
    "        data = torch.Tensor(self.csv.iloc[: , 1: -1].values)\n",
    "        label = torch.Tensor(self.csv.iloc[: , -1].values.reshape(-1, 1))\n",
    "        self.data = StandardScaler().fit_transform(data)\n",
    "        # 정답이 숫자 크다면 정규화가 학습에 도움이 된다.\n",
    "        self.label = StandardScaler().fit_transform(label)\n",
    "        self.data = torch.Tensor(self.data)\n",
    "        self.label = torch.Tensor(self.label)\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 30 # 사용가능한 배치 개수\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index: index + 30]\n",
    "        label = self.label[index + 30]\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(StockDataSet()))\n",
    "data.size(), label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70498b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class StockRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StockRNN, self).__init__()\n",
    "        # (30일, 배치 16개, 각 입력의 특성 4개) batch_first = False\n",
    "        # (배치 16개, 30일 각 입력의 특성 4개) batch_first = True\n",
    "        self.rnn = nn.RNN(input_size=4, hidden_size=8, num_layers=5, batch_first=True)\n",
    "        # 출력 (batch, 30, 8)\n",
    "        self.fc1 = nn.Linear(30*8, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x, ho): # 입력데이터는 (16,30,4)\n",
    "        # ho = 초기 은닉 상태(num_layers, batch, hidden_size) (5,16,8)\n",
    "        # 출력 x 는 모든 시점에 대한 hidden output을 담고 있어야함 (batch, seq_len, hidden_size) (16,30,8)\n",
    "        # 출력 hn 최종은닉상태(각 레이어의 마지막 타임스탬프 hidden state) (num_layer, batch, hidden_state) (5,16,8)\n",
    "        x, hn = self.rnn(x, ho)\n",
    "        # mlp 입력으로 사용될 수 있도록 모양 변경\n",
    "        x = torch.reshape(x, (x.shape[0], -1))\n",
    "        # mlp \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # 예측한 종가 1차원 벡터\n",
    "        out = torch.flatten(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = StockRNN()\n",
    "sample_data = torch.randn(16, 30, 4)\n",
    "# 초기 hidden state 값  (num_layer, batch_size, hidden_size) (5, 16, 8)\n",
    "ho = torch.zeros(5,16,8)\n",
    "out = rnn(sample_data, ho)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = StockRNN().to(device)\n",
    "dataset = StockDataSet()\n",
    "loader = DataLoader(dataset, batch_size=16)\n",
    "optim = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected hidden size (5,9,8) got [5,16,8]\n",
    "# Rnn이 처리하는 배치크기는 9, 우리가 설계한 ho 16\n",
    "print(len(dataset) % 16)\n",
    "# 마지막 배치 개수가 모자라서 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(200):\n",
    "    loop = tqdm(loader)\n",
    "    for data, label in loop:\n",
    "        optim.zero_grad() # 학습 다 끝냈는데 이전 기울기가 남아있는 상황 방지\n",
    "        # 초기 은닉 상태의 배치크기는 DataLoader가 주는 배치 크기\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        ho = torch.zeros(5,batch_size,8).to(device)\n",
    "        # 모델의 예측값\n",
    "        pred = model(data.to(device), ho)\n",
    "        # 손실값\n",
    "        loss = nn.MSELoss()(pred, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f'epoch: {epoch+1} loss: {loss.item()}')\n",
    "torch.save(model.state_dict(), './rnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능평가하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loader = DataLoader(dataset,batch_size=1)\n",
    "preds = []\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    model.load_state_dict(torch.load('rnn.pth', map_location=device,weights_only=False))\n",
    "    for data, label in loader:\n",
    "        # 초기 은닉상태의 배치크기는 DataLoader가 주는 배치 크기\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        ho = torch.zeros(5,batch_size,8).to(device)\n",
    "        # 모델의 예측값\n",
    "        pred = model(data.to(device), ho)\n",
    "        preds.append(pred.item())\n",
    "        # 손실값\n",
    "        loss = nn.MSELoss()(pred, label.to(device))\n",
    "        total_loss += (loss.item() / len(loader))\n",
    "\n",
    "print(f'total_loss : {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d529c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(preds, label='preds')\n",
    "plt.plot(dataset.label, label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01151353",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_30 = df.iloc[-30:, 1:-1].values\n",
    "    X = torch.tensor(last_30, dtype=torch.float32).unsqueeze(0)\n",
    "    ho = torch.zeros(5,1,8).to(device)\n",
    "    pred = model(X.to(device), ho)\n",
    "    print(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6becd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfinance\n",
    "X = np.array([\n",
    "    [10,20],[100,200]\n",
    "])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d46ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0780b126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>424.810745</td>\n",
       "      <td>429.942234</td>\n",
       "      <td>422.627126</td>\n",
       "      <td>428.731323</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>434.180393</td>\n",
       "      <td>435.232492</td>\n",
       "      <td>428.880188</td>\n",
       "      <td>429.306976</td>\n",
       "      <td>29749100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 00:00:00-04:00</th>\n",
       "      <td>412.264861</td>\n",
       "      <td>413.058918</td>\n",
       "      <td>403.272376</td>\n",
       "      <td>403.322021</td>\n",
       "      <td>53971000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01 00:00:00-04:00</th>\n",
       "      <td>405.962252</td>\n",
       "      <td>412.403882</td>\n",
       "      <td>404.463494</td>\n",
       "      <td>407.312103</td>\n",
       "      <td>24230400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-04 00:00:00-05:00</th>\n",
       "      <td>406.746332</td>\n",
       "      <td>407.361738</td>\n",
       "      <td>402.547872</td>\n",
       "      <td>405.416321</td>\n",
       "      <td>19672300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-10-29 00:00:00-04:00  424.810745  429.942234  422.627126  428.731323   \n",
       "2024-10-30 00:00:00-04:00  434.180393  435.232492  428.880188  429.306976   \n",
       "2024-10-31 00:00:00-04:00  412.264861  413.058918  403.272376  403.322021   \n",
       "2024-11-01 00:00:00-04:00  405.962252  412.403882  404.463494  407.312103   \n",
       "2024-11-04 00:00:00-05:00  406.746332  407.361738  402.547872  405.416321   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-10-29 00:00:00-04:00  17644100        0.0           0.0  \n",
       "2024-10-30 00:00:00-04:00  29749100        0.0           0.0  \n",
       "2024-10-31 00:00:00-04:00  53971000        0.0           0.0  \n",
       "2024-11-01 00:00:00-04:00  24230400        0.0           0.0  \n",
       "2024-11-04 00:00:00-05:00  19672300        0.0           0.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "dat = yf.Ticker(\"MSFT\")\n",
    "df = dat.history(period='1y')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df877b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수, 종속변수 분리\n",
    "# window size : 30(한달치 데이터를 하나의 dataset)\n",
    "# 배치는 3배치\n",
    "# 알고리즘은 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ceba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "class YFieldDataSet(Dataset):\n",
    "    def __init__(self):\n",
    "        self.csv = df\n",
    "        # print(self.csv.iloc[: , : 4].values)\n",
    "        # print(self.csv.columns[:4])\n",
    "        data = torch.Tensor(self.csv.iloc[: , :4].values)\n",
    "        label = torch.Tensor(self.csv.iloc[: , 4].values.reshape(-1, 1))\n",
    "        self.data = StandardScaler().fit_transform(data)\n",
    "        # 정답이 숫자 크다면 정규화가 학습에 도움이 된다.\n",
    "        self.label = StandardScaler().fit_transform(label)\n",
    "        self.data = torch.Tensor(self.data)\n",
    "        self.label = torch.Tensor(self.label)\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 30 # 사용가능한 배치 개수\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index: index + 30]\n",
    "        label = self.label[index + 30]\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class YFieldRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YFieldRNN, self).__init__()\n",
    "        # (30일, 배치 16개, 각 입력의 특성 4개) batch_first = False\n",
    "        # (배치 16개, 30일 각 입력의 특성 4개) batch_first = True\n",
    "        self.rnn = nn.RNN(input_size=4, hidden_size=8, num_layers=5, batch_first=True)\n",
    "        # 출력 (batch, 30, 8)\n",
    "        self.fc1 = nn.Linear(30*8, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x, ho): # 입력데이터는 (16,30,4)\n",
    "        # ho = 초기 은닉 상태(num_layers, batch, hidden_size) (5,16,8)\n",
    "        # 출력 x 는 모든 시점에 대한 hidden output을 담고 있어야함 (batch, seq_len, hidden_size) (16,30,8)\n",
    "        # 출력 hn 최종은닉상태(각 레이어의 마지막 타임스탬프 hidden state) (num_layer, batch, hidden_state) (5,16,8)\n",
    "        x, hn = self.rnn(x, ho)\n",
    "        # mlp 입력으로 사용될 수 있도록 모양 변경\n",
    "        x = torch.reshape(x, (x.shape[0], -1))\n",
    "        # mlp \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # 예측한 종가 1차원 벡터\n",
    "        out = torch.flatten(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ac28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = YFieldRNN()\n",
    "sample_data = torch.randn(3, 30, 4)\n",
    "ho = torch.zeros(5,3,8)\n",
    "out = rnn(sample_data, ho)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = YFieldRNN().to(device)\n",
    "dataset = YFieldDataSet()\n",
    "loader = DataLoader(dataset, batch_size=3)\n",
    "optim = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(200):\n",
    "    loop = tqdm(loader)\n",
    "    for data, label in loop:\n",
    "        optim.zero_grad() # 학습 다 끝냈는데 이전 기울기가 남아있는 상황 방지\n",
    "        # 초기 은닉 상태의 배치크기는 DataLoader가 주는 배치 크기\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        ho = torch.zeros(5,batch_size,8).to(device)\n",
    "        # 모델의 예측값\n",
    "        pred = model(data.to(device), ho)\n",
    "        # 손실값\n",
    "        loss = nn.MSELoss()(pred, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f'epoch: {epoch+1} loss: {loss.item()}')\n",
    "torch.save(model.state_dict(), './yfinance.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능평가하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loader = DataLoader(dataset,batch_size=1)\n",
    "preds = []\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    model.load_state_dict(torch.load('yfinance.pth', map_location=device,weights_only=False))\n",
    "    for data, label in loader:\n",
    "        # 초기 은닉상태의 배치크기는 DataLoader가 주는 배치 크기\n",
    "        batch_size = data.size(0)\n",
    "\n",
    "        ho = torch.zeros(5,batch_size,8).to(device)\n",
    "        # 모델의 예측값\n",
    "        pred = model(data.to(device), ho)\n",
    "        preds.append(pred.item())\n",
    "        # 손실값\n",
    "        loss = nn.MSELoss()(pred, label.to(device))\n",
    "        total_loss += (loss.item() / len(loader))\n",
    "\n",
    "print(f'total_loss : {total_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
